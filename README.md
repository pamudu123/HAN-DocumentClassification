# Hierarchical Attention Networks (HAN) for Document Classification

> **Paper**: Hierarchical Attention Networks for Document Classification (2016)  
> **Authors**: Zichao Yang, Diyi Yang, Chris Dyer, Xiaodong He, Alex Smola, Eduard Hovy

### üìÑ Research Paper
[Hierarchical Attention Networks for Document Classification](https://www.cs.cmu.edu/~hovy/papers/16HLT-hierarchical-attention-networks.pdf)

### üé• Video Presentation
[HAN Document Classification Presentation](https://www.youtube.com/watch?v=JfgFRSjEucE&t=43s&ab_channel=PamuduRanasinghe)

## Model Overview
**Key Features of this approach:**
- Hierarchical document structure modeling (words ‚Üí sentences ‚Üí documents)
- Dual attention mechanisms for words and sentences
- Superior performance on document classification tasks
- Interpretable attention weights for understanding model decisions

### üí° Key Innovation

> *"This hierarchical approach mirrors human reading comprehension with sentences followed by words and gives attention to important words and sentences. Very creative idea!"*

## üìñ References

1. **Yang, Z., Yang, D., Dyer, C., He, X., Smola, A., & Hovy, E.** (2016). *Hierarchical Attention Networks for Document Classification*. In Proceedings of NAACL-HLT. [[PDF]](https://www.cs.cmu.edu/~hovy/papers/16HLT-hierarchical-attention-networks.pdf)
2. **Medentsiy, V.** *Document Representations*. University of Amsterdam. [[Slides]](https://cl-illc.github.io/semantics/resources/slides/DocumentRepresentations.pdf)

**üìß Contact**: For questions or collaborations, feel free to reach out through the YouTube channel or GitHub.

**‚≠ê Star this repository** if you find it helpful for your research or studies!

`You are welcome to use any of the slides, vector images, and SVG image codes for your academic work.`

## üñºÔ∏è Presentation Slides
![Slide 1 - Title](presentation_slides/slide1.PNG)
![Slide 2 - Introduction](presentation_slides/slide2.PNG)
![Slide 3 - Motivation](presentation_slides/slide3.PNG)
![Slide 4 - Problem Statement](presentation_slides/slide4.PNG)
![Slide 5 - Architecture Overview](presentation_slides/slide5.PNG)
![Slide 6 - Word Encoder](presentation_slides/slide6.PNG)
![Slide 7 - Word Attention](presentation_slides/slide7.PNG)
![Slide 8 - Sentence Encoder](presentation_slides/slide8.PNG)
![Slide 9 - Sentence Attention](presentation_slides/slide9.PNG)
![Slide 10 - Document Classification](presentation_slides/slide10.PNG)
![Slide 11 - Experimental Setup](presentation_slides/slide11.PNG)
![Slide 12 - Results](presentation_slides/slide12.PNG)
![Slide 13 - Analysis](presentation_slides/slide13.PNG)
![Slide 14 - Visualization](presentation_slides/slide14.PNG)
![Slide 15 - Conclusion](presentation_slides/slide15.PNG)